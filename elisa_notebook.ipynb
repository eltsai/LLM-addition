{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Models Use Trigonometry to Do Addition\n",
    "\n",
    "## **Objective**\n",
    "The goal of this study is to investigate how transformers utilize **hidden state representations** to perform fundamental mathematical operations such as **addition**. Specifically, the study explores:\n",
    "1. **How numbers are represented within the residual stream** across multiple layers.\n",
    "2. **How attention and MLP mechanisms interact** to modify and propagate numerical representations.\n",
    "3. **What underlying algorithms transformers learn** to perform arithmetic operations.\n",
    "\n",
    " <img src=\"fig1.jpg\" width=\"600\"/>\n",
    "\n",
    "\n",
    "## Problem Definition\n",
    "\n",
    "### **Background**\n",
    "Autoregressive transformers are widely used in language models to process sequential data by predicting the next token in a given sequence. These models take as input a sequence of tokens $x_0, ..., x_n$ and generate probability distributions over possible next tokens $x_{n+1}$, enabling tasks such as text generation, mathematical reasoning, and code completion.\n",
    "\n",
    "### **Formal Definition**\n",
    "Given a sequence of tokens $x_0, x_1, ..., x_n$, an autoregressive transformer processes each token through a **residual stream** comprising multiple layers of computation. Each layer consists of two primary components: **multi-head self-attention** and **multi-layer perceptrons (MLPs)**. The hidden state representation at layer $l$ for token $i$ is computed as:\n",
    "\n",
    "$$\n",
    "h^l_i = h^{l-1}_i + a^l_i + m^l_i\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $h^l_i$ represents the hidden state at layer $l$ for token $i$,\n",
    "- $a^l_i$ is the output of the **attention mechanism**, computed as:\n",
    "\n",
    "  $$\n",
    "  a^l_i = \\text{attn}^l(h^{l-1}_1, h^{l-1}_2, ..., h^{l-1}_i)\n",
    "  $$\n",
    "\n",
    "- $m^l_i$ is the output of the **MLP component**, computed as:\n",
    "\n",
    "  $$\n",
    "  m^l_i = \\text{MLP}^l(a^l_i + h^{l-1}_i)\n",
    "  $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eltsai/anaconda3/envs/llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "from nnsight import LanguageModel\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pickle\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "import itertools\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at EleutherAI/gpt-j-6B were not used when initializing GPTJForCausalLM: ['transformer.h.0.attn.bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.10.attn.bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.12.attn.bias', 'transformer.h.12.attn.masked_bias', 'transformer.h.13.attn.bias', 'transformer.h.13.attn.masked_bias', 'transformer.h.14.attn.bias', 'transformer.h.14.attn.masked_bias', 'transformer.h.15.attn.bias', 'transformer.h.15.attn.masked_bias', 'transformer.h.16.attn.bias', 'transformer.h.16.attn.masked_bias', 'transformer.h.17.attn.bias', 'transformer.h.17.attn.masked_bias', 'transformer.h.18.attn.bias', 'transformer.h.18.attn.masked_bias', 'transformer.h.19.attn.bias', 'transformer.h.19.attn.masked_bias', 'transformer.h.2.attn.bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.20.attn.bias', 'transformer.h.20.attn.masked_bias', 'transformer.h.21.attn.bias', 'transformer.h.21.attn.masked_bias', 'transformer.h.22.attn.bias', 'transformer.h.22.attn.masked_bias', 'transformer.h.23.attn.bias', 'transformer.h.23.attn.masked_bias', 'transformer.h.24.attn.bias', 'transformer.h.24.attn.masked_bias', 'transformer.h.25.attn.bias', 'transformer.h.25.attn.masked_bias', 'transformer.h.26.attn.bias', 'transformer.h.26.attn.masked_bias', 'transformer.h.27.attn.bias', 'transformer.h.27.attn.masked_bias', 'transformer.h.3.attn.bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.bias', 'transformer.h.9.attn.masked_bias']\n",
      "- This IS expected if you are initializing GPTJForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPTJForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model# Set the token as an environment variable\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "full_model_name = 'EleutherAI/gpt-j-6B'#'meta-llama/Llama-3.1-8B'# #'EleutherAI/pythia-6.9b'## # #'google/gemma-2-9b'#'\n",
    "MODEL_NAME = full_model_name.split('/')[-1]\n",
    "model = LanguageModel(full_model_name, device_map=device, torch_dtype=torch.bfloat16, dispatch=True)\n",
    "remote = False\n",
    "NLAYERS = model.config.num_hidden_layers\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTJForCausalLM(\n",
       "  (transformer): GPTJModel(\n",
       "    (wte): Embedding(50400, 4096)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-27): 28 x GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=50400, bias=True)\n",
       "  (generator): Generator(\n",
       "    (streamer): Streamer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"transformers.png\" alt=\"Transformers architecture\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate addition evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 140.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>q_string</th>\n",
       "      <th>q_tok</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Output ONLY a number.\\n0+0=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 15, 10, 15,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Output ONLY a number.\\n0+1=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 15, 10, 16,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Output ONLY a number.\\n0+2=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 15, 10, 17,...</td>\n",
       "      <td>2</td>\n",
       "      <td>[17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Output ONLY a number.\\n0+3=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 15, 10, 18,...</td>\n",
       "      <td>3</td>\n",
       "      <td>[18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Output ONLY a number.\\n0+4=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 15, 10, 19,...</td>\n",
       "      <td>4</td>\n",
       "      <td>[19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>99</td>\n",
       "      <td>95</td>\n",
       "      <td>Output ONLY a number.\\n99+95=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 2079, 10, 3...</td>\n",
       "      <td>194</td>\n",
       "      <td>[22913]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>99</td>\n",
       "      <td>96</td>\n",
       "      <td>Output ONLY a number.\\n99+96=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 2079, 10, 4...</td>\n",
       "      <td>195</td>\n",
       "      <td>[22186]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>99</td>\n",
       "      <td>97</td>\n",
       "      <td>Output ONLY a number.\\n99+97=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 2079, 10, 5...</td>\n",
       "      <td>196</td>\n",
       "      <td>[25272]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "      <td>Output ONLY a number.\\n99+98=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 2079, 10, 4...</td>\n",
       "      <td>197</td>\n",
       "      <td>[24991]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>Output ONLY a number.\\n99+99=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 2079, 10, 2...</td>\n",
       "      <td>198</td>\n",
       "      <td>[22337]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       a   b                       q_string  \\\n",
       "0      0   0    Output ONLY a number.\\n0+0=   \n",
       "1      0   1    Output ONLY a number.\\n0+1=   \n",
       "2      0   2    Output ONLY a number.\\n0+2=   \n",
       "3      0   3    Output ONLY a number.\\n0+3=   \n",
       "4      0   4    Output ONLY a number.\\n0+4=   \n",
       "...   ..  ..                            ...   \n",
       "9995  99  95  Output ONLY a number.\\n99+95=   \n",
       "9996  99  96  Output ONLY a number.\\n99+96=   \n",
       "9997  99  97  Output ONLY a number.\\n99+97=   \n",
       "9998  99  98  Output ONLY a number.\\n99+98=   \n",
       "9999  99  99  Output ONLY a number.\\n99+99=   \n",
       "\n",
       "                                                  q_tok  answer answer_tok  \n",
       "0     [26410, 22224, 257, 1271, 13, 198, 15, 10, 15,...       0       [15]  \n",
       "1     [26410, 22224, 257, 1271, 13, 198, 15, 10, 16,...       1       [16]  \n",
       "2     [26410, 22224, 257, 1271, 13, 198, 15, 10, 17,...       2       [17]  \n",
       "3     [26410, 22224, 257, 1271, 13, 198, 15, 10, 18,...       3       [18]  \n",
       "4     [26410, 22224, 257, 1271, 13, 198, 15, 10, 19,...       4       [19]  \n",
       "...                                                 ...     ...        ...  \n",
       "9995  [26410, 22224, 257, 1271, 13, 198, 2079, 10, 3...     194    [22913]  \n",
       "9996  [26410, 22224, 257, 1271, 13, 198, 2079, 10, 4...     195    [22186]  \n",
       "9997  [26410, 22224, 257, 1271, 13, 198, 2079, 10, 5...     196    [25272]  \n",
       "9998  [26410, 22224, 257, 1271, 13, 198, 2079, 10, 4...     197    [24991]  \n",
       "9999  [26410, 22224, 257, 1271, 13, 198, 2079, 10, 2...     198    [22337]  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "def gen_math(mina = 0, maxa = 99):\n",
    "    data = []\n",
    "    with torch.no_grad():\n",
    "        for a in tqdm(range(mina, maxa + 1)):\n",
    "            for b in range(mina, maxa + 1):\n",
    "                if MODEL_NAME == 'gpt-j-6B':\n",
    "                    q_string = f'Output ONLY a number.\\n{a}+{b}='\n",
    "                elif MODEL_NAME == 'Llama-3.1-8B':\n",
    "                    q_string = f'The following is a correct addition problem. \\n{a}+{b}='\n",
    "                    #q_string = f'The following is a correction addition problem. {a}+0='\n",
    "                elif MODEL_NAME == 'pythia-6.9b':\n",
    "                    q_string = f'Output ONLY a number. {a}+{b}='\n",
    "                q_toks = model.tokenizer(q_string)['input_ids']\n",
    "                answer = a+b\n",
    "                answer_tok = model.tokenizer(f'{answer}')['input_ids']\n",
    "                if MODEL_NAME == 'Llama-3.1-8B':\n",
    "                    answer_tok = [answer_tok[-1]]\n",
    "                #print(answer_tok)\n",
    "                data.append({\n",
    "                    'a': a,\n",
    "                    'b': b,\n",
    "                    'q_string': q_string,\n",
    "                    'q_tok': q_toks,\n",
    "                    'answer': answer,\n",
    "                    'answer_tok': answer_tok\n",
    "                })\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_pickle(f'data_addition/gen_math/data_addition_{mina}_{maxa}_{MODEL_NAME}.pkl')\n",
    "    return df\n",
    "\n",
    "\n",
    "#evaluate_math(mina = 0, maxa = 500)\n",
    "gen_math(mina = 0, maxa = 99)\n",
    "#data = get_math_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_math(mina = 0, maxa = 99, verbose = False, batch_size = 100):\n",
    "    df = pd.read_pickle(f'data_addition/gen_math/data_addition_{mina}_{maxa}_{MODEL_NAME}.pkl')\n",
    "    #df = df.sample(n=15, random_state=42)\n",
    "    corrects = []\n",
    "    with torch.no_grad():\n",
    "        # Process rows in batches\n",
    "        bar = tqdm(range(0, len(df), batch_size))\n",
    "        for step in bar:\n",
    "            batch_df = df.iloc[step:min(step + batch_size, len(df))]\n",
    "            batch_toks = torch.stack([torch.tensor(x) for x in batch_df['q_tok'].values]).to(device)\n",
    "            # Combine into single batch tensor\n",
    "            answer_toks = torch.stack([torch.tensor(x)[0] for x in batch_df['answer_tok'].values])\n",
    "            # Get model outputs for batch\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(batch_toks) as invoker:\n",
    "                    pass\n",
    "                output = model.output.save()\n",
    "            \n",
    "            # Get predictions for batch\n",
    "            logits = output.logits[:,-1].cpu()\n",
    "            #print(model.tokenizer.batch_decode(output.logits[0].argmax(dim=-1)))\n",
    "            model_answers = logits.argmax(dim=-1)\n",
    "            correct = (model_answers == answer_toks).float()\n",
    "            incorrect_mask = correct == 0\n",
    "            if incorrect_mask.any() and verbose:\n",
    "                print(\"Incorrect answers:\")\n",
    "                print(\"Expected:\", model.tokenizer.batch_decode(answer_toks[incorrect_mask].unsqueeze(-1)))\n",
    "                print(\"Got:\", model.tokenizer.batch_decode(model_answers[incorrect_mask].unsqueeze(-1)))\n",
    "            corrects.extend(list(correct))\n",
    "            bar.set_postfix({'%': np.mean(corrects)})\n",
    "            \n",
    "    df['correct'] = corrects\n",
    "    df.to_pickle(f'data_addition/gen_math/data_addition_correct_{mina}_{maxa}_{MODEL_NAME}.pkl')\n",
    "    return np.mean(corrects)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 100/100 [00:14<00:00,  6.85it/s, %=0.806]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8061"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_math(mina = 0, maxa = 99, verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_df(mina = 0, maxa = 99):\n",
    "    df = pd.read_pickle(f'data_addition/gen_math/data_addition_correct_{mina}_{maxa}_{MODEL_NAME}.pkl')\n",
    "    return df[df['correct'] == 1]\n",
    "\n",
    "def get_df_sample(mina = 0, maxa = 99, num_sample = 500, run = False):\n",
    "    if run:\n",
    "        df = get_correct_df(mina, maxa)\n",
    "        df = df.sample(n=num_sample, random_state=42).reset_index(drop=True)\n",
    "        # Save sampled dataframe\n",
    "        save_path = f'data_addition/gen_math/data_addition_correct_sample_{mina}_{maxa}_{MODEL_NAME}.pkl'\n",
    "        df.to_pickle(save_path)\n",
    "    return pd.read_pickle(f'data_addition/gen_math/data_addition_correct_sample_{mina}_{maxa}_{MODEL_NAME}.pkl')\n",
    "\n",
    "def get_output_tokens(mina = 0, maxa = 99):\n",
    "    # answers range from 0, 99 * 2 \n",
    "    avals, toks = [], []\n",
    "    for a in range(mina, 2 * maxa + 1):\n",
    "        atok = model.tokenizer(f'{a}')['input_ids']\n",
    "        avals.append(a)\n",
    "        toks.append(atok[0])\n",
    "    return avals, toks\n",
    "\n",
    "a, toks = get_output_tokens()\n",
    "df = get_df_sample(run = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>q_string</th>\n",
       "      <th>q_tok</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_tok</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>Output ONLY a number.\\n9+51=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 24, 10, 434...</td>\n",
       "      <td>60</td>\n",
       "      <td>[1899]</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>39</td>\n",
       "      <td>Output ONLY a number.\\n25+39=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 1495, 10, 2...</td>\n",
       "      <td>64</td>\n",
       "      <td>[2414]</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>Output ONLY a number.\\n45+49=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 2231, 10, 2...</td>\n",
       "      <td>94</td>\n",
       "      <td>[5824]</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>54</td>\n",
       "      <td>Output ONLY a number.\\n56+54=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 3980, 10, 4...</td>\n",
       "      <td>110</td>\n",
       "      <td>[11442]</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77</td>\n",
       "      <td>15</td>\n",
       "      <td>Output ONLY a number.\\n77+15=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 3324, 10, 1...</td>\n",
       "      <td>92</td>\n",
       "      <td>[5892]</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Output ONLY a number.\\n4+4=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 19, 10, 19,...</td>\n",
       "      <td>8</td>\n",
       "      <td>[23]</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>75</td>\n",
       "      <td>15</td>\n",
       "      <td>Output ONLY a number.\\n75+15=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 2425, 10, 1...</td>\n",
       "      <td>90</td>\n",
       "      <td>[3829]</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "      <td>Output ONLY a number.\\n74+11=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 4524, 10, 1...</td>\n",
       "      <td>85</td>\n",
       "      <td>[5332]</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>Output ONLY a number.\\n62+5=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 5237, 10, 2...</td>\n",
       "      <td>67</td>\n",
       "      <td>[3134]</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>28</td>\n",
       "      <td>54</td>\n",
       "      <td>Output ONLY a number.\\n28+54=</td>\n",
       "      <td>[26410, 22224, 257, 1271, 13, 198, 2078, 10, 4...</td>\n",
       "      <td>82</td>\n",
       "      <td>[6469]</td>\n",
       "      <td>tensor(1.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      a   b                       q_string  \\\n",
       "0     9  51   Output ONLY a number.\\n9+51=   \n",
       "1    25  39  Output ONLY a number.\\n25+39=   \n",
       "2    45  49  Output ONLY a number.\\n45+49=   \n",
       "3    56  54  Output ONLY a number.\\n56+54=   \n",
       "4    77  15  Output ONLY a number.\\n77+15=   \n",
       "..   ..  ..                            ...   \n",
       "495   4   4    Output ONLY a number.\\n4+4=   \n",
       "496  75  15  Output ONLY a number.\\n75+15=   \n",
       "497  74  11  Output ONLY a number.\\n74+11=   \n",
       "498  62   5   Output ONLY a number.\\n62+5=   \n",
       "499  28  54  Output ONLY a number.\\n28+54=   \n",
       "\n",
       "                                                 q_tok  answer answer_tok  \\\n",
       "0    [26410, 22224, 257, 1271, 13, 198, 24, 10, 434...      60     [1899]   \n",
       "1    [26410, 22224, 257, 1271, 13, 198, 1495, 10, 2...      64     [2414]   \n",
       "2    [26410, 22224, 257, 1271, 13, 198, 2231, 10, 2...      94     [5824]   \n",
       "3    [26410, 22224, 257, 1271, 13, 198, 3980, 10, 4...     110    [11442]   \n",
       "4    [26410, 22224, 257, 1271, 13, 198, 3324, 10, 1...      92     [5892]   \n",
       "..                                                 ...     ...        ...   \n",
       "495  [26410, 22224, 257, 1271, 13, 198, 19, 10, 19,...       8       [23]   \n",
       "496  [26410, 22224, 257, 1271, 13, 198, 2425, 10, 1...      90     [3829]   \n",
       "497  [26410, 22224, 257, 1271, 13, 198, 4524, 10, 1...      85     [5332]   \n",
       "498  [26410, 22224, 257, 1271, 13, 198, 5237, 10, 2...      67     [3134]   \n",
       "499  [26410, 22224, 257, 1271, 13, 198, 2078, 10, 4...      82     [6469]   \n",
       "\n",
       "        correct  \n",
       "0    tensor(1.)  \n",
       "1    tensor(1.)  \n",
       "2    tensor(1.)  \n",
       "3    tensor(1.)  \n",
       "4    tensor(1.)  \n",
       "..          ...  \n",
       "495  tensor(1.)  \n",
       "496  tensor(1.)  \n",
       "497  tensor(1.)  \n",
       "498  tensor(1.)  \n",
       "499  tensor(1.)  \n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANS_SEQPOS_DICT\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  9.85it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "target = 'b'\n",
    "mina = 0\n",
    "maxa = 99\n",
    "batch_size = 80\n",
    "sample = False\n",
    "\n",
    "ANS_SEQPOS = ANS_SEQPOS_DICT[target]\n",
    "\n",
    "a = torch.tensor(df['a'].values)\n",
    "b = torch.tensor(df['b'].values)\n",
    "a_b = a+b\n",
    "hss = []\n",
    "with torch.no_grad():\n",
    "    for step in tqdm(range(0, len(df), batch_size)):\n",
    "        batch_df = df.iloc[step:min(step + batch_size, len(df))]\n",
    "        tokens = torch.stack([torch.tensor(x) for x in batch_df['q_tok'].values]).to(device)\n",
    "        layer_hss = []\n",
    "        with model.trace(validate=False,remote=remote) as tracer:\n",
    "            with tracer.invoke(tokens, scan=False):\n",
    "                for layer in range(NLAYERS):\n",
    "                    if MODEL_NAME == 'Llama-3.1-8B':\n",
    "                        hs = model.model.layers[layer].input\n",
    "                    elif MODEL_NAME == 'gpt-j-6B':\n",
    "                        hs = model.transformer.h[layer].inputs[1]['hidden_states']\n",
    "                    elif MODEL_NAME == 'pythia-6.9b':\n",
    "                        hs = model.gpt_neox.layers[layer].input\n",
    "                    layer_hss.append(hs[:,ANS_SEQPOS].save())\n",
    "        layer_hss = [layer_hs.detach().cpu() for layer_hs in layer_hss] # gets hs on top of ans_token\n",
    "        layer_hss = torch.stack(layer_hss, dim=1) # stack along new layer dimension\n",
    "        hss.append(layer_hss)\n",
    "hss = torch.cat(hss, dim=0) # concat along batch dimension\n",
    "# Save nums and hss to file with descriptive name\n",
    "# Use _FULL in filename if using complete dataset\n",
    "suffix = '_FULL' if not sample else ''\n",
    "save_path = f'data/helix_hss/{target}_helix_data_{mina}_{maxa}{suffix}_{MODEL_NAME}.pt'\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs('data/helix_hss', exist_ok=True)\n",
    "# Save tensors\n",
    "torch.save({\n",
    "    'a': a,\n",
    "    'b':b,\n",
    "    'a+b':a_b,\n",
    "    'hidden_states': hss\n",
    "}, save_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run_hs('a', sample = False)\n",
    "#run_hs('a', sample = True)\n",
    "#get_nums_hss('a', sample = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nums_hss(target, mina = 0,maxa = 99, sample = False):\n",
    "    suffix = '_FULL' if not sample else ''\n",
    "    save_path = f'data/helix_hss/{target}_helix_data_{mina}_{maxa}{suffix}_{MODEL_NAME}.pt'\n",
    "    obj = torch.load(save_path, weights_only=True)\n",
    "    a,b,a_b, hss = obj['a'], obj['b'], obj['a+b'], obj['hidden_states']\n",
    "    return a,b,a_b, hss\n",
    "\n",
    "a,b,a_b, hss = get_nums_hss('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 28, 4096])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:17<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "def run_pca(target, mina = 0, maxa = 99, NUM_PCA = 100):\n",
    "    _,_,_, hss = get_nums_hss(target, mina, maxa) # we want the full thing for a pca\n",
    "    pca_components = {}\n",
    "    for layer in tqdm(range(hss.shape[1])):\n",
    "        hs = hss[:,layer]\n",
    "        # Convert to numpy for sklearn\n",
    "        hs_numpy = hs.float().numpy()\n",
    "        # Fit PCA without dimensionality reduction\n",
    "        pca = PCA(n_components=NUM_PCA)# None\n",
    "        pca.fit(hs_numpy)\n",
    "        # Store components for this layer\n",
    "        pca_components[layer] = {\n",
    "            'explained_variance_ratio': pca.explained_variance_ratio_,\n",
    "            'components': pca.components_,\n",
    "            'singular_values': pca.singular_values_,\n",
    "            'mean': pca.mean_\n",
    "        }\n",
    "    # Save PCA components to file with descriptive name\n",
    "    save_path = f'data/helix_pca/{target}_pca_data_{mina}_{maxa}_{MODEL_NAME}.pt'\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs('data/helix_pca', exist_ok=True)\n",
    "    # Save dictionary\n",
    "    torch.save(pca_components, save_path)\n",
    "    return pca_components\n",
    "\n",
    "def get_pca(target, layer, mina = 0, maxa = 99):\n",
    "    save_path = f'data/helix_pca/{target}_pca_data_{mina}_{maxa}_{MODEL_NAME}.pt'\n",
    "    pca_data = torch.load(save_path, weights_only = False)[layer]\n",
    "    return pca_data\n",
    "\n",
    "run_pca('b')\n",
    "pca_data = get_pca('b', 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating Numerical Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated hidden states for 100\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 406.25x142.188 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "COL_WIDTH = 3.25\n",
    "TWO_COL_WIDTH = 6.75\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 10,               # Default text size\n",
    "    'axes.titlesize': 7,          # Title size for axes\n",
    "    'axes.labelsize': 7,          # Axis label size\n",
    "    'xtick.labelsize': 6,         # X-axis tick label size\n",
    "    'ytick.labelsize': 6,         # Y-axis tick label size\n",
    "    'legend.fontsize': 6,         # Legend font size\n",
    "    'figure.titlesize': 10,        # Overall figure title size\n",
    "})\n",
    "def get_nums_hidden_states(mina = 0,maxa = 99):\n",
    "    nums = np.linspace(mina, maxa, maxa-mina+1)\n",
    "    tokens = torch.tensor(model.tokenizer([f'{int(num)}' for num in nums])['input_ids'])\n",
    "    activations = []\n",
    "    with torch.no_grad():\n",
    "        with model.trace(validate=False,remote=remote) as tracer:\n",
    "            with tracer.invoke(tokens, scan=False):\n",
    "                for layer in range(NLAYERS):\n",
    "                    activations.append(model.transformer.h[layer].inputs[1]['hidden_states'][:,-1].save())\n",
    "    act = torch.stack(activations).detach().cpu()\n",
    "    print(f'Generated hidden states for {len(nums)}')\n",
    "    return nums, act\n",
    "\n",
    "\n",
    "\n",
    "def get_pc1(mina, maxa, skip0, layer):\n",
    "    nums, hss = get_nums_hidden_states(mina, maxa)\n",
    "    hs = hss[layer].cpu().float().numpy()\n",
    "    # Perform PCA\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    hs_scaled = scaler.fit_transform(hs)\n",
    "    \n",
    "    # Get first principal component\n",
    "    pca = PCA(n_components=1)\n",
    "    pc1_vals = pca.fit_transform(hs_scaled).flatten()\n",
    "    \n",
    "    # Print variance explained by PC1\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=(1.25*COL_WIDTH, 1.25*0.35*COL_WIDTH))\n",
    "    \n",
    "    # Create scatter plot colored by number value\n",
    "    scatter = plt.scatter(nums, pc1_vals, c=nums, cmap='viridis', label = 'PC1')\n",
    "    \n",
    "    # Calculate line of best fit\n",
    "    slope, intercept = np.polyfit(nums, pc1_vals, 1)\n",
    "    line_x = nums\n",
    "    line_y = slope * line_x + intercept\n",
    "    \n",
    "    # Calculate R^2\n",
    "    r_squared = np.corrcoef(nums, pc1_vals)[0,1]**2\n",
    "    \n",
    "    # Plot line of best fit\n",
    "    plt.plot(line_x, line_y, 'r--', label=f'Best fit (R² = {r_squared:.3f})')\n",
    "    \n",
    "    # Add colorbar\n",
    "    plt.colorbar(scatter)\n",
    "    \n",
    "    plt.xlabel('Number')\n",
    "    plt.ylabel('PC1 Value')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    # Create directory if it doesn't exist\n",
    "    # Save figure with informative filename\n",
    "    # plt.savefig(f'paper_figures/figure_2/pc1_layer{layer-1}_range{mina}-{maxa}_skip0={skip0}_{MODEL_NAME}.pdf', \n",
    "    #             bbox_inches='tight', dpi = 300)\n",
    "    plt.show()\n",
    "\n",
    "get_pc1(mina = 0, maxa = 99, skip0 = False, layer = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
