{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "from nnsight import LanguageModel\n",
    "import plotly.graph_objects as go\n",
    "#from pyvene import BoundlessRotatedSpaceIntervention\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset as hf_Dataset\n",
    "from transformers import get_linear_schedule_with_warmup, AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from einops import einsum, repeat, reduce\n",
    "plt.rcParams.update({\n",
    "    'font.size': 6,               # Default text size\n",
    "    'axes.titlesize': 7,          # Title size for axes\n",
    "    'axes.labelsize': 7,          # Axis label size\n",
    "    'xtick.labelsize': 6,         # X-axis tick label size\n",
    "    'ytick.labelsize': 6,         # Y-axis tick label size\n",
    "    'legend.fontsize': 6,         # Legend font size\n",
    "    'figure.titlesize': 10,        # Overall figure title size\n",
    "})\n",
    "mapping = {'helix_a_b':'helix(a,b)', 'helix_ab': 'helix(a+b)', 'helix_a_b_ab': 'helix(a,b,a+b)', 'pca_27': '27dim PCA', 'pca_9': '9dim PCA', 'exchange': 'Layer Patch'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 47.53 GiB of which 14.69 MiB is free. Process 1663678 has 6.98 GiB memory in use. Process 1664812 has 23.93 GiB memory in use. Process 1665837 has 6.98 GiB memory in use. Including non-PyTorch memory, this process has 9.61 GiB memory in use. Of the allocated memory 9.35 GiB is allocated by PyTorch, and 589.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m full_model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEleutherAI/gpt-j-6B\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m MODEL_NAME \u001b[38;5;241m=\u001b[39m full_model_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLanguageModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or you can use \"auto\" for automatic device mapping\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Add this if you're still getting warnings\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m remote \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     13\u001b[0m NLAYERS \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers\n",
      "File \u001b[0;32m~/number-helix/helix/lib/python3.12/site-packages/nnsight/models/LanguageModel.py:160\u001b[0m, in \u001b[0;36mLanguageModel.__init__\u001b[0;34m(self, model_key, tokenizer, automodel, *args, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_key, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(model_key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m\"\u001b[39m, WrapperModule())\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/number-helix/helix/lib/python3.12/site-packages/nnsight/models/NNsightModel.py:119\u001b[0m, in \u001b[0;36mNNsight.__init__\u001b[0;34m(self, model_key, dispatch, meta_buffers, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_envoy \u001b[38;5;241m=\u001b[39m Envoy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dispatch \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatched:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# Dispatch ._model on initialization vs lazy dispatching.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialized `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/number-helix/helix/lib/python3.12/site-packages/nnsight/models/NNsightModel.py:494\u001b[0m, in \u001b[0;36mNNsight.dispatch_model\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Dispatch ._model to have real parameters  using ._load(...).\"\"\"\u001b[39;00m\n\u001b[1;32m    492\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDispatching `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_envoy\u001b[38;5;241m.\u001b[39m_update(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model)\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/number-helix/helix/lib/python3.12/site-packages/nnsight/models/LanguageModel.py:212\u001b[0m, in \u001b[0;36mLanguageModel._load\u001b[0;34m(self, repo_id, tokenizer_kwargs, patch_llama_scan, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    205\u001b[0m     patch_llama_scan\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, LlamaConfig)\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config\u001b[38;5;241m.\u001b[39mrope_scaling, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrope_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrope_scaling\n\u001b[1;32m    209\u001b[0m ):\n\u001b[1;32m    210\u001b[0m     config\u001b[38;5;241m.\u001b[39mrope_scaling[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrope_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 212\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28msetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m\"\u001b[39m, WrapperModule())\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/number-helix/helix/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/number-helix/helix/lib/python3.12/site-packages/transformers/modeling_utils.py:4264\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4254\u001b[0m         load_contexts\u001b[38;5;241m.\u001b[39mappend(tp_device)\n\u001b[1;32m   4256\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(load_contexts):\n\u001b[1;32m   4257\u001b[0m         (\n\u001b[1;32m   4258\u001b[0m             model,\n\u001b[1;32m   4259\u001b[0m             missing_keys,\n\u001b[1;32m   4260\u001b[0m             unexpected_keys,\n\u001b[1;32m   4261\u001b[0m             mismatched_keys,\n\u001b[1;32m   4262\u001b[0m             offload_index,\n\u001b[1;32m   4263\u001b[0m             error_msgs,\n\u001b[0;32m-> 4264\u001b[0m         ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4265\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4266\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4267\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   4268\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4269\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4270\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4271\u001b[0m \u001b[43m            \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4272\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4273\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4274\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4275\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4276\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4277\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4278\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4281\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4282\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4284\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   4285\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/number-helix/helix/lib/python3.12/site-packages/transformers/modeling_utils.py:4777\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path, weights_only)\u001b[0m\n\u001b[1;32m   4773\u001b[0m                 set_module_tensor_to_device(\n\u001b[1;32m   4774\u001b[0m                     model_to_load, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39msize(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   4775\u001b[0m                 )\n\u001b[1;32m   4776\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4777\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4778\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4779\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4780\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4781\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4782\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4783\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4784\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4785\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4786\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4791\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4793\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   4794\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4795\u001b[0m     \u001b[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001b[39;00m\n",
      "File \u001b[0;32m~/number-helix/helix/lib/python3.12/site-packages/transformers/modeling_utils.py:942\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys, pretrained_model_name_or_path)\u001b[0m\n\u001b[1;32m    939\u001b[0m         param_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m     \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mset_module_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    944\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)\n",
      "File \u001b[0;32m~/number-helix/helix/lib/python3.12/site-packages/accelerate/utils/modeling.py:329\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    327\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 329\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 47.53 GiB of which 14.69 MiB is free. Process 1663678 has 6.98 GiB memory in use. Process 1664812 has 23.93 GiB memory in use. Process 1665837 has 6.98 GiB memory in use. Including non-PyTorch memory, this process has 9.61 GiB memory in use. Of the allocated memory 9.35 GiB is allocated by PyTorch, and 589.50 KiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Just pass string instead of torch.device\n",
    "full_model_name = 'EleutherAI/gpt-j-6B'\n",
    "MODEL_NAME = full_model_name.split('/')[-1]\n",
    "model = LanguageModel(\n",
    "    full_model_name,\n",
    "    device_map=device,  # or you can use \"auto\" for automatic device mapping\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    dispatch=True,\n",
    "    trust_remote_code=True  # Add this if you're still getting warnings\n",
    ")\n",
    "remote = False\n",
    "NLAYERS = model.config.num_hidden_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and Evaluate\n",
    "Need to generate math problems and make sure the model can get them right before we move onto any analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: BAD TOKENIZATION ON 521\n",
      "WARNING: BAD TOKENIZATION ON 527\n",
      "WARNING: BAD TOKENIZATION ON 531\n",
      "WARNING: BAD TOKENIZATION ON 532\n",
      "WARNING: BAD TOKENIZATION ON 534\n",
      "WARNING: BAD TOKENIZATION ON 539\n",
      "WARNING: BAD TOKENIZATION ON 541\n",
      "WARNING: BAD TOKENIZATION ON 542\n",
      "WARNING: BAD TOKENIZATION ON 543\n",
      "WARNING: BAD TOKENIZATION ON 547\n",
      "WARNING: BAD TOKENIZATION ON 564\n",
      "WARNING: BAD TOKENIZATION ON 566\n",
      "WARNING: BAD TOKENIZATION ON 567\n",
      "WARNING: BAD TOKENIZATION ON 569\n",
      "WARNING: BAD TOKENIZATION ON 611\n",
      "WARNING: BAD TOKENIZATION ON 619\n",
      "WARNING: BAD TOKENIZATION ON 621\n",
      "WARNING: BAD TOKENIZATION ON 622\n",
      "WARNING: BAD TOKENIZATION ON 624\n",
      "WARNING: BAD TOKENIZATION ON 631\n",
      "WARNING: BAD TOKENIZATION ON 632\n",
      "WARNING: BAD TOKENIZATION ON 633\n",
      "WARNING: BAD TOKENIZATION ON 634\n",
      "WARNING: BAD TOKENIZATION ON 636\n",
      "WARNING: BAD TOKENIZATION ON 637\n",
      "WARNING: BAD TOKENIZATION ON 638\n",
      "WARNING: BAD TOKENIZATION ON 639\n",
      "WARNING: BAD TOKENIZATION ON 664\n",
      "WARNING: BAD TOKENIZATION ON 711\n",
      "WARNING: BAD TOKENIZATION ON 715\n",
      "WARNING: BAD TOKENIZATION ON 716\n",
      "WARNING: BAD TOKENIZATION ON 717\n",
      "WARNING: BAD TOKENIZATION ON 719\n",
      "WARNING: BAD TOKENIZATION ON 721\n",
      "WARNING: BAD TOKENIZATION ON 722\n",
      "WARNING: BAD TOKENIZATION ON 723\n",
      "WARNING: BAD TOKENIZATION ON 724\n",
      "WARNING: BAD TOKENIZATION ON 726\n",
      "WARNING: BAD TOKENIZATION ON 731\n",
      "WARNING: BAD TOKENIZATION ON 732\n",
      "WARNING: BAD TOKENIZATION ON 734\n",
      "WARNING: BAD TOKENIZATION ON 735\n",
      "WARNING: BAD TOKENIZATION ON 737\n",
      "WARNING: BAD TOKENIZATION ON 738\n",
      "WARNING: BAD TOKENIZATION ON 739\n",
      "WARNING: BAD TOKENIZATION ON 741\n",
      "WARNING: BAD TOKENIZATION ON 742\n",
      "WARNING: BAD TOKENIZATION ON 743\n",
      "WARNING: BAD TOKENIZATION ON 744\n",
      "WARNING: BAD TOKENIZATION ON 746\n",
      "WARNING: BAD TOKENIZATION ON 749\n",
      "WARNING: BAD TOKENIZATION ON 761\n",
      "WARNING: BAD TOKENIZATION ON 764\n",
      "WARNING: BAD TOKENIZATION ON 766\n",
      "WARNING: BAD TOKENIZATION ON 769\n",
      "WARNING: BAD TOKENIZATION ON 788\n",
      "WARNING: BAD TOKENIZATION ON 791\n",
      "WARNING: BAD TOKENIZATION ON 811\n",
      "WARNING: BAD TOKENIZATION ON 812\n",
      "WARNING: BAD TOKENIZATION ON 813\n",
      "WARNING: BAD TOKENIZATION ON 814\n",
      "WARNING: BAD TOKENIZATION ON 816\n",
      "WARNING: BAD TOKENIZATION ON 817\n",
      "WARNING: BAD TOKENIZATION ON 818\n",
      "WARNING: BAD TOKENIZATION ON 819\n",
      "WARNING: BAD TOKENIZATION ON 821\n",
      "WARNING: BAD TOKENIZATION ON 822\n",
      "WARNING: BAD TOKENIZATION ON 823\n",
      "WARNING: BAD TOKENIZATION ON 824\n",
      "WARNING: BAD TOKENIZATION ON 826\n",
      "WARNING: BAD TOKENIZATION ON 827\n",
      "WARNING: BAD TOKENIZATION ON 828\n",
      "WARNING: BAD TOKENIZATION ON 829\n",
      "WARNING: BAD TOKENIZATION ON 831\n",
      "WARNING: BAD TOKENIZATION ON 832\n",
      "WARNING: BAD TOKENIZATION ON 834\n",
      "WARNING: BAD TOKENIZATION ON 835\n",
      "WARNING: BAD TOKENIZATION ON 836\n",
      "WARNING: BAD TOKENIZATION ON 837\n",
      "WARNING: BAD TOKENIZATION ON 838\n",
      "WARNING: BAD TOKENIZATION ON 839\n",
      "WARNING: BAD TOKENIZATION ON 841\n",
      "WARNING: BAD TOKENIZATION ON 842\n",
      "WARNING: BAD TOKENIZATION ON 843\n",
      "WARNING: BAD TOKENIZATION ON 844\n",
      "WARNING: BAD TOKENIZATION ON 845\n",
      "WARNING: BAD TOKENIZATION ON 846\n",
      "WARNING: BAD TOKENIZATION ON 847\n",
      "WARNING: BAD TOKENIZATION ON 848\n",
      "WARNING: BAD TOKENIZATION ON 849\n",
      "WARNING: BAD TOKENIZATION ON 851\n",
      "WARNING: BAD TOKENIZATION ON 852\n",
      "WARNING: BAD TOKENIZATION ON 853\n",
      "WARNING: BAD TOKENIZATION ON 854\n",
      "WARNING: BAD TOKENIZATION ON 856\n",
      "WARNING: BAD TOKENIZATION ON 857\n",
      "WARNING: BAD TOKENIZATION ON 858\n",
      "WARNING: BAD TOKENIZATION ON 859\n",
      "WARNING: BAD TOKENIZATION ON 861\n",
      "WARNING: BAD TOKENIZATION ON 862\n",
      "WARNING: BAD TOKENIZATION ON 863\n",
      "WARNING: BAD TOKENIZATION ON 865\n",
      "WARNING: BAD TOKENIZATION ON 867\n",
      "WARNING: BAD TOKENIZATION ON 868\n",
      "WARNING: BAD TOKENIZATION ON 869\n",
      "WARNING: BAD TOKENIZATION ON 871\n",
      "WARNING: BAD TOKENIZATION ON 872\n",
      "WARNING: BAD TOKENIZATION ON 873\n",
      "WARNING: BAD TOKENIZATION ON 874\n",
      "WARNING: BAD TOKENIZATION ON 876\n",
      "WARNING: BAD TOKENIZATION ON 878\n",
      "WARNING: BAD TOKENIZATION ON 879\n",
      "WARNING: BAD TOKENIZATION ON 881\n",
      "WARNING: BAD TOKENIZATION ON 890\n",
      "WARNING: BAD TOKENIZATION ON 891\n",
      "WARNING: BAD TOKENIZATION ON 892\n",
      "WARNING: BAD TOKENIZATION ON 894\n",
      "WARNING: BAD TOKENIZATION ON 895\n",
      "WARNING: BAD TOKENIZATION ON 897\n",
      "WARNING: BAD TOKENIZATION ON 898\n",
      "WARNING: BAD TOKENIZATION ON 902\n",
      "WARNING: BAD TOKENIZATION ON 903\n",
      "WARNING: BAD TOKENIZATION ON 904\n",
      "WARNING: BAD TOKENIZATION ON 906\n",
      "WARNING: BAD TOKENIZATION ON 907\n",
      "WARNING: BAD TOKENIZATION ON 908\n",
      "WARNING: BAD TOKENIZATION ON 912\n",
      "WARNING: BAD TOKENIZATION ON 913\n",
      "WARNING: BAD TOKENIZATION ON 914\n",
      "WARNING: BAD TOKENIZATION ON 917\n",
      "WARNING: BAD TOKENIZATION ON 918\n",
      "WARNING: BAD TOKENIZATION ON 919\n",
      "WARNING: BAD TOKENIZATION ON 921\n",
      "WARNING: BAD TOKENIZATION ON 922\n",
      "WARNING: BAD TOKENIZATION ON 923\n",
      "WARNING: BAD TOKENIZATION ON 924\n",
      "WARNING: BAD TOKENIZATION ON 926\n",
      "WARNING: BAD TOKENIZATION ON 927\n",
      "WARNING: BAD TOKENIZATION ON 928\n",
      "WARNING: BAD TOKENIZATION ON 929\n",
      "WARNING: BAD TOKENIZATION ON 931\n",
      "WARNING: BAD TOKENIZATION ON 932\n",
      "WARNING: BAD TOKENIZATION ON 933\n",
      "WARNING: BAD TOKENIZATION ON 934\n",
      "WARNING: BAD TOKENIZATION ON 935\n",
      "WARNING: BAD TOKENIZATION ON 936\n",
      "WARNING: BAD TOKENIZATION ON 937\n",
      "WARNING: BAD TOKENIZATION ON 938\n",
      "WARNING: BAD TOKENIZATION ON 939\n",
      "WARNING: BAD TOKENIZATION ON 941\n",
      "WARNING: BAD TOKENIZATION ON 942\n",
      "WARNING: BAD TOKENIZATION ON 943\n",
      "WARNING: BAD TOKENIZATION ON 944\n",
      "WARNING: BAD TOKENIZATION ON 945\n",
      "WARNING: BAD TOKENIZATION ON 946\n",
      "WARNING: BAD TOKENIZATION ON 947\n",
      "WARNING: BAD TOKENIZATION ON 948\n",
      "WARNING: BAD TOKENIZATION ON 955\n",
      "WARNING: BAD TOKENIZATION ON 957\n",
      "WARNING: BAD TOKENIZATION ON 958\n",
      "WARNING: BAD TOKENIZATION ON 959\n",
      "WARNING: BAD TOKENIZATION ON 961\n",
      "WARNING: BAD TOKENIZATION ON 962\n",
      "WARNING: BAD TOKENIZATION ON 963\n",
      "WARNING: BAD TOKENIZATION ON 964\n",
      "WARNING: BAD TOKENIZATION ON 965\n",
      "WARNING: BAD TOKENIZATION ON 966\n",
      "WARNING: BAD TOKENIZATION ON 967\n",
      "WARNING: BAD TOKENIZATION ON 971\n",
      "WARNING: BAD TOKENIZATION ON 972\n",
      "WARNING: BAD TOKENIZATION ON 973\n",
      "WARNING: BAD TOKENIZATION ON 974\n",
      "WARNING: BAD TOKENIZATION ON 976\n",
      "WARNING: BAD TOKENIZATION ON 977\n",
      "WARNING: BAD TOKENIZATION ON 979\n",
      "WARNING: BAD TOKENIZATION ON 981\n",
      "WARNING: BAD TOKENIZATION ON 982\n",
      "WARNING: BAD TOKENIZATION ON 983\n",
      "WARNING: BAD TOKENIZATION ON 984\n",
      "WARNING: BAD TOKENIZATION ON 988\n",
      "WARNING: BAD TOKENIZATION ON 991\n"
     ]
    }
   ],
   "source": [
    "def ensure_proper_tokenization(mina = 0, maxa = 99):\n",
    "    # makes sure all numbers are tokenized as 1 token in the range we care about\n",
    "    ideal_len = 1\n",
    "    with torch.no_grad():\n",
    "        for a in range(mina, maxa + 1):\n",
    "            actual_len = len(model.tokenizer(f'{a}')['input_ids'])\n",
    "            #actual_len = len([1:])\n",
    "            if actual_len != ideal_len:\n",
    "                print(f'WARNING: BAD TOKENIZATION ON {a}')\n",
    "ensure_proper_tokenization(maxa = 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_gen_math\u001b[39m(mina \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, maxa \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m99\u001b[39m):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_addition/gen_math/data_addition_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmina\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmaxa\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mgen_math\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmina\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxa\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m99\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m, in \u001b[0;36mgen_math\u001b[0;34m(mina, maxa)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgen_math\u001b[39m(mina \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, maxa \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m99\u001b[39m):\n\u001b[1;32m      2\u001b[0m     data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(mina, maxa \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(mina, maxa \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "def gen_math(mina = 0, maxa = 99):\n",
    "    data = []\n",
    "    with torch.no_grad():\n",
    "        for a in tqdm(range(mina, maxa + 1)):\n",
    "            for b in range(mina, maxa + 1):\n",
    "                q_string = f'Output ONLY a number.\\n{a}+{b}='\n",
    "                q_toks = model.tokenizer(q_string)['input_ids']\n",
    "                answer = a+b\n",
    "                answer_tok = model.tokenizer(f'{answer}')['input_ids']\n",
    "                data.append({\n",
    "                    'a': a,\n",
    "                    'b': b,\n",
    "                    'q_string': q_string,\n",
    "                    'q_tok': q_toks,\n",
    "                    'answer': answer,\n",
    "                    'answer_tok': answer_tok\n",
    "                })\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_pickle(f'data_addition/gen_math/data_addition_{mina}_{maxa}.pkl')\n",
    "    return df\n",
    "\n",
    "def get_gen_math(mina = 0, maxa = 99):\n",
    "    return pd.read_pickle(f'data_addition/gen_math/data_addition_{mina}_{maxa}.pkl')\n",
    "\n",
    "gen_math(mina = 0, maxa = 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "  0%|          | 40/10000 [00:02<10:48, 15.36it/s, a+b=0+39, ans=39, correct=1, percent=1.000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m     plt\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     50\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 52\u001b[0m \u001b[43mevaluate_math\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmina\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxa\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m99\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m plot_math_results()\n",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m, in \u001b[0;36mevaluate_math\u001b[0;34m(mina, maxa, verbose)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m---> 16\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m prediction \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     18\u001b[0m right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(prediction \u001b[38;5;241m==\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer_tok\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def evaluate_math(mina = 0, maxa = 99, verbose = False):\n",
    "    df = pd.read_pickle(f'data_addition/gen_math/data_addition_{mina}_{maxa}.pkl')\n",
    "    #df = df.sample(n=15, random_state=42)\n",
    "    correct = []\n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        rows.append(row)\n",
    "    bar = tqdm(rows)\n",
    "    with torch.no_grad():\n",
    "        for row in bar:\n",
    "            toks = torch.tensor(row['q_tok']).to('cuda')\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(toks) as invoker: # gets the corrupt hs to patch in\n",
    "                    pass\n",
    "                output = model.output.save()\n",
    "            logits = output.logits[:,-1].cpu()\n",
    "            prediction = logits.argmax(dim=-1).item()\n",
    "            right = int(prediction == row['answer_tok'][0])\n",
    "            correct.append(right)\n",
    "            if not right and verbose:\n",
    "                print(row['a'], row['b'])\n",
    "                print(model.tokenizer.batch_decode([prediction]), row['answer'])\n",
    "            bar.set_postfix({'a+b':f'{row['a']}+{row['b']}', 'ans': row['answer'], 'correct': right, 'percent': f'{np.mean(correct):.3f}'})\n",
    "    del logits\n",
    "    df['correct'] = correct\n",
    "    df.to_pickle(f'data_addition/gen_math/data_addition_correct_{mina}_{maxa}.pkl')\n",
    "    return np.mean(correct)\n",
    "\n",
    "def plot_math_results(mina = 0, maxa = 99):    \n",
    "    model_name = MODEL_NAME\n",
    "    df = pd.read_pickle(f'data_addition/gen_math/data_addition_correct_{mina}_{maxa}.pkl')\n",
    "    \n",
    "    # Print accuracies for different ranges\n",
    "    for max_val in [25, 50, 75, 100]:\n",
    "        filtered_df = df[(df['a'] <= max_val) & (df['b'] <= max_val)]\n",
    "        acc = 100 * np.mean(filtered_df['correct'])\n",
    "        print(f\"Accuracy for numbers up to {max_val}: {acc:.2f}%\")\n",
    "    \n",
    "    plt.figure(figsize=(5, 5))\n",
    "    # Create a scatter plot\n",
    "    scatter = plt.scatter(df['a'], df['b'], c=df['correct'].replace({1: 1, 0: -1}), cmap='RdBu', s=100, vmin = -2, vmax = 2)\n",
    "    # Add colorbar\n",
    "    plt.colorbar(scatter, ticks=[-1, 1], label='Correctness')\n",
    "    plt.title(f'{model_name} Results on a+b= (Blue if correct)\\n{100*np.mean(df['correct']):.2f}% Correct')\n",
    "    plt.xlabel('a')\n",
    "    plt.ylabel('b')\n",
    "    plt.xlim(mina, maxa)\n",
    "    plt.ylim(mina, maxa)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "evaluate_math(mina = 0, maxa = 99, verbose = False)\n",
    "plot_math_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervention Dataset Generation\n",
    "We want to use only the prompts we got correct for interventions (to reduce noise, make results meaningful)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_df(mina = 0, maxa = 99):\n",
    "    df = pd.read_pickle(f'data_addition/gen_math/data_addition_correct_{mina}_{maxa}.pkl')\n",
    "    return df[df['correct'] == 1]\n",
    "\n",
    "def gen_intervention(samplesize = 1000, run = False, mina = 0, maxa = 99):\n",
    "    if run:\n",
    "        df = get_correct_df(mina = mina, maxa = maxa)\n",
    "        print(len(df))\n",
    "        # Drop the 'correct' column since we only have correct examples now\n",
    "        df = df.drop('correct', axis=1)\n",
    "        # Create cartesian product of df with itself\n",
    "        intervention_df = df.merge(df, how='cross', suffixes=('_original', '_intervened'))\n",
    "        # Filter out cases where original answer equals intervened answer\n",
    "        intervention_df = intervention_df[intervention_df['answer_original'] != intervention_df['answer_intervened']]\n",
    "        # Take random sample of size samplesize\n",
    "        intervention_df = intervention_df.sample(n=samplesize, random_state=42).reset_index(drop = True)\n",
    "        # Save to pickle file\n",
    "        intervention_df.to_pickle(f'data_addition/data_intervention_{mina}_{maxa}_sample{samplesize}.pkl')\n",
    "    intervention_df = pd.read_pickle(f'data_addition/data_intervention_{mina}_{maxa}_sample{samplesize}.pkl')\n",
    "    return intervention_df\n",
    "\n",
    "df_int = gen_intervention(run = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer interventions\n",
    "Start simple and build up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logit_diff(patched_logits, og_logits, cor_answer_tokens):\n",
    "    # Get logit differences between patched and original logits for each answer token\n",
    "    patched_target =  patched_logits[torch.arange(len(cor_answer_tokens)), cor_answer_tokens]\n",
    "    og_target = og_logits[torch.arange(len(cor_answer_tokens)), cor_answer_tokens]\n",
    "    logit_diffs = patched_target - og_target\n",
    "    return logit_diffs\n",
    "\n",
    "def calc_correct(patched_logits, cor_answer_tokens):\n",
    "    # Get logit differences between patched and original logits for each answer token\n",
    "    patched_answers = patched_logits.argmax(dim=-1)\n",
    "    return (patched_answers == cor_answer_tokens).to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 3/28 [00:06<00:55,  2.22s/it, layer=2, logit_diff=0.0075, accuracy=0] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 95\u001b[0m\n\u001b[1;32m     92\u001b[0m         plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m patch_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlps\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 95\u001b[0m     \u001b[43mact_patch_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_to_use\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpatch_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     plot_act_patch_all(patch_type \u001b[38;5;241m=\u001b[39m patch_type)\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[29], line 62\u001b[0m, in \u001b[0;36mact_patch_all\u001b[0;34m(df, patch_type, num_to_use)\u001b[0m\n\u001b[1;32m     60\u001b[0m bar \u001b[38;5;241m=\u001b[39m tqdm(layers)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m bar:\n\u001b[0;32m---> 62\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43mact_patch_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_to_use\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_to_use\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpatch_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     results[layer] \u001b[38;5;241m=\u001b[39m metrics\n\u001b[1;32m     64\u001b[0m     bar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m:layer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetrics})\n",
      "Cell \u001b[0;32mIn[29], line 49\u001b[0m, in \u001b[0;36mact_patch_batch\u001b[0;34m(layer, df, batch_size, num_to_use, patch_type)\u001b[0m\n\u001b[1;32m     47\u001b[0m batch_corrupt \u001b[38;5;241m=\u001b[39m corrupt_tokens[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m     48\u001b[0m batch_corrupt_answers \u001b[38;5;241m=\u001b[39m corrupt_answer_tokens[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m---> 49\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mact_patch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_corrupt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_corrupt_answers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpatch_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m combined_results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     combined_results \u001b[38;5;241m=\u001b[39m {key:results[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mkeys()}\n",
      "File \u001b[0;32m~/number-helix/helix/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 30\u001b[0m, in \u001b[0;36mact_patch\u001b[0;34m(layer, clean_tokens, corrupt_tokens, cor_answer_tokens, patch_type)\u001b[0m\n\u001b[1;32m     28\u001b[0m             model\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mh[layer]\u001b[38;5;241m.\u001b[39mattn\u001b[38;5;241m.\u001b[39moutput[\u001b[38;5;241m0\u001b[39m][all_inds, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;241m=\u001b[39m patch_hs\n\u001b[1;32m     29\u001b[0m     patched_output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m---> 30\u001b[0m clean_logits \u001b[38;5;241m=\u001b[39m \u001b[43mclean_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m patched_logits \u001b[38;5;241m=\u001b[39m patched_output\u001b[38;5;241m.\u001b[39mlogits[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     32\u001b[0m log_diff \u001b[38;5;241m=\u001b[39m calc_logit_diff(patched_logits, clean_logits, cor_answer_tokens)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "@torch.no_grad()  \n",
    "def act_patch(layer, clean_tokens, corrupt_tokens, cor_answer_tokens, patch_type = 'layers'):\n",
    "    batch_size = len(cor_answer_tokens)\n",
    "    all_inds = torch.arange(batch_size)\n",
    "    with model.trace() as tracer:\n",
    "        with tracer.invoke(clean_tokens) as invoker_clean: # gets the clean tokens for calculation\n",
    "            pass\n",
    "        clean_output = model.output.save()\n",
    "        with tracer.invoke(corrupt_tokens) as invoker_corrupt: # gets the corrupt hs to patch in\n",
    "            if patch_type == 'layers':\n",
    "                corrupt_hs = model.transformer.h[layer].output[0].save()\n",
    "            elif patch_type == 'mlps':\n",
    "                #corrupt_hs = model.transformer.h[layer].mlp.output.save()\n",
    "                corrupt_hs = model.transformer.h[layer].mlp.act.input.save()\n",
    "            elif patch_type == 'attention':\n",
    "                corrupt_hs = model.transformer.h[layer].attn.output[0].save()\n",
    "            else:\n",
    "                raise ValueError(f'Invalid patch type {patch_type}')\n",
    "    with model.trace(validate = False) as tracer:\n",
    "        with tracer.invoke(clean_tokens) as invoker_patch: # puts corrupt hs into clean run\n",
    "            patch_hs = corrupt_hs[all_inds,-1,:].detach().to('cuda')\n",
    "            if patch_type == 'layers':\n",
    "                model.transformer.h[layer].output[0][all_inds, -1, :] = patch_hs\n",
    "            elif patch_type == 'mlps':\n",
    "                #model.transformer.h[layer].mlp.output[all_inds, -1, :] = patch_hs\n",
    "                model.transformer.h[layer].mlp.act.input[all_inds, -1, :] = patch_hs\n",
    "            elif patch_type == 'attention':\n",
    "                model.transformer.h[layer].attn.output[0][all_inds, -1, :] = patch_hs\n",
    "        patched_output = model.output.save()\n",
    "    clean_logits = clean_output.logits[:batch_size,-1].cpu()\n",
    "    patched_logits = patched_output.logits[:,-1].cpu()\n",
    "    log_diff = calc_logit_diff(patched_logits, clean_logits, cor_answer_tokens)\n",
    "    correct = calc_correct(patched_logits, cor_answer_tokens)\n",
    "    metrics = {'logit_diff':log_diff, 'accuracy': correct}\n",
    "    return metrics\n",
    "\n",
    "def act_patch_batch(layer, df, batch_size=8, num_to_use = None, patch_type = 'layers'):\n",
    "    if num_to_use is not None:\n",
    "        df = df.sample(n=num_to_use, random_state=42)\n",
    "    clean_tokens = torch.stack([torch.tensor(x) for x in df['q_tok_original'].values])\n",
    "    corrupt_tokens = torch.stack([torch.tensor(x) for x in df['q_tok_intervened'].values])\n",
    "    corrupt_answer_tokens = torch.stack([torch.tensor(x[0]) for x in df['answer_tok_intervened'].values])\n",
    "    combined_results = None\n",
    "\n",
    "    for i in range(0, len(clean_tokens), batch_size):\n",
    "        batch_clean = clean_tokens[i:i+batch_size].to('cuda')\n",
    "        batch_corrupt = corrupt_tokens[i:i+batch_size].to('cuda') \n",
    "        batch_corrupt_answers = corrupt_answer_tokens[i:i+batch_size]\n",
    "        results = act_patch(layer, batch_clean, batch_corrupt, batch_corrupt_answers, patch_type = patch_type)\n",
    "        if combined_results is None:\n",
    "            combined_results = {key:results[key] for key in results.keys()}\n",
    "        else: \n",
    "            combined_results = {key: torch.cat([combined_results[key], results[key]]) for key in combined_results.keys()}\n",
    "    combined_results = {key: torch.mean(combined_results[key]).item() for key in combined_results.keys()} # take mean at the end\n",
    "    return combined_results\n",
    "\n",
    "def act_patch_all(df, patch_type = 'layers', num_to_use = None):\n",
    "    results = {}\n",
    "    layers = list(range(NLAYERS))\n",
    "    bar = tqdm(layers)\n",
    "    for layer in bar:\n",
    "        metrics = act_patch_batch(layer, df, num_to_use = num_to_use, patch_type = patch_type)\n",
    "        results[layer] = metrics\n",
    "        bar.set_postfix({'layer':layer, **metrics})\n",
    "    save_data = {\n",
    "        'results': results,\n",
    "        'layers': layers\n",
    "    }\n",
    "    with open(f'data/act_patching/act_patching_results_all_{patch_type}.pkl', 'wb') as f:\n",
    "        pickle.dump(save_data, f)\n",
    "    return results\n",
    "\n",
    "def plot_act_patch_all(patch_type = 'layers'):\n",
    "    with open(f'data/act_patching/act_patching_results_all_{patch_type}.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    results = data['results'] \n",
    "    layers = data['layers']\n",
    "    \n",
    "    metrics = list(next(iter(results.values())).keys())\n",
    "    \n",
    "    for metric in metrics:\n",
    "        plt.figure(figsize=(4,3))\n",
    "        values = [results[layer][metric] for layer in layers]\n",
    "        plt.plot(layers, values, '-o')\n",
    "        plt.xlabel('Layer')\n",
    "        plt.ylabel(metric.replace('_',' ').title())\n",
    "        plt.title(f'Activation Patching {patch_type}: {metric.replace(\"_\",\" \").title()}')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f'figs_addition/act_patching/act_patch_{patch_type}_{metric}.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "for patch_type in ['mlps', 'attention', 'layers']:\n",
    "    act_patch_all(df_int, num_to_use = 100, patch_type = patch_type)\n",
    "    plot_act_patch_all(patch_type = patch_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribution Patching\n",
    "TODO: Patch MLPs in a way that allows me to see how neurons affect it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:54<00:00,  2.28it/s]\n"
     ]
    }
   ],
   "source": [
    "def attpatch_logit_diff(cor_logits, og_logits, og_answer_tokens):\n",
    "    # Get logit differences between patched and original logits for each answer token\n",
    "    indices = torch.arange(len(og_answer_tokens)).to(cor_logits.device)\n",
    "    cor_target =  cor_logits[indices, og_answer_tokens]\n",
    "    og_target = og_logits[indices, og_answer_tokens]\n",
    "    logit_diffs = cor_target #- og_target\n",
    "    return logit_diffs.mean()\n",
    "\n",
    "def att_patch(clean_tokens, corrupted_tokens, clean_answer_tokens):\n",
    "    clean_out = []\n",
    "    corrupted_out = []\n",
    "    corrupted_grads = []\n",
    "\n",
    "    with model.trace() as tracer:\n",
    "        with tracer.invoke(clean_tokens) as invoker_clean:\n",
    "            # Gather each layer's attention\n",
    "            for layer in model.transformer.h:\n",
    "                mlp = layer.mlp.fc_out.input\n",
    "                clean_out.append(mlp.save())\n",
    "            og_logits = model.lm_head.output.save()[:,-1].cpu()\n",
    "        with tracer.invoke(corrupted_tokens) as invoker_corrupted:\n",
    "            # Gather each layer's attention and gradients\n",
    "            for layer in model.transformer.h:\n",
    "                mlp = layer.mlp.fc_out.input\n",
    "                corrupted_out.append(mlp.save())\n",
    "                # save corrupted gradients for attribution patching\n",
    "                corrupted_grads.append(mlp.grad.save())\n",
    "            cor_logits = model.lm_head.output.save()[:,-1].cpu()\n",
    "            value = attpatch_logit_diff(cor_logits, og_logits, clean_answer_tokens)\n",
    "            value.backward()\n",
    "    return clean_out, corrupted_out, corrupted_grads\n",
    "\n",
    "\n",
    "def att_patch_all(df, batch_size = 8):\n",
    "    clean_tokens = torch.stack([torch.tensor(x) for x in df['q_tok_original'].values])\n",
    "    corrupt_tokens = torch.stack([torch.tensor(x) for x in df['q_tok_intervened'].values])\n",
    "    clean_answer_tokens = torch.stack([torch.tensor(x[0]) for x in df['answer_tok_original'].values])\n",
    "\n",
    "    total_samples = len(clean_tokens)\n",
    "    num_batches = (total_samples + batch_size - 1) // batch_size  # Ceiling division\n",
    "    total_results = None\n",
    "\n",
    "    for batch in tqdm(range(num_batches)):\n",
    "        start_idx = batch * batch_size\n",
    "        end_idx = min(start_idx + batch_size, total_samples)  # Handle final partial batch\n",
    "        \n",
    "        batch_clean = clean_tokens[start_idx:end_idx]\n",
    "        batch_corrupt = corrupt_tokens[start_idx:end_idx] \n",
    "        batch_answers = clean_answer_tokens[start_idx:end_idx]\n",
    "\n",
    "        clean_mlps, corrupt_mlps, corrupt_grads = att_patch(batch_clean, batch_corrupt, batch_answers)\n",
    "\n",
    "        batch_results = []\n",
    "        for corrupted_grad, corrupted, clean, layer in zip(\n",
    "            corrupt_grads, corrupt_mlps, clean_mlps, range(len(clean_mlps))\n",
    "        ):\n",
    "                \n",
    "            res = (corrupted_grad.value * (clean.value - corrupted.value))[:,-1].detach().cpu().float()\n",
    "            # Sum over batch dimension\n",
    "            summed_res = res.sum(dim=0)\n",
    "            batch_results.append(summed_res)\n",
    "\n",
    "        batch_results = torch.stack(batch_results)\n",
    "        if total_results is None:\n",
    "            total_results = batch_results\n",
    "        else:\n",
    "            total_results += batch_results\n",
    "\n",
    "        del corrupt_grads, corrupt_mlps, clean_mlps\n",
    "\n",
    "    # Divide by actual total number of samples processed\n",
    "    total_results = total_results / num_batches # not total_num bc of how gradients are accumulated\n",
    "    return total_results\n",
    "\n",
    "total_results = att_patch_all(df_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the results of attribution patching and sanity checking MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1245)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_mlp_attpatch(total_results):\n",
    "    layers = list(range(total_results.shape[0]))\n",
    "    print(total_results[19].sum())\n",
    "    att_patch_logdiff = []\n",
    "    for layer in layers:\n",
    "        att_patch_logdiff.append(total_results[layer].sum())\n",
    "    plt.figure(figsize = (5,4))\n",
    "    plt.plot(layers, att_patch_logdiff, marker = 'o')\n",
    "    plt.title('MLP Logit Difference By Summing Neurons Attribution Patch')\n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylabel('Estimated Logit Difference')\n",
    "    plt.grid()\n",
    "    plt.savefig('figs_addition/att_patch_mlp_estimate.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_neurons_attpatch(total_results):\n",
    "    layers = list(range(total_results.shape[0]))\n",
    "    att_patch_logdiff = []\n",
    "    for layer in layers:\n",
    "        neuron_indices = range(total_results[layer].shape[0])\n",
    "        plt.figure(figsize=(5,4))\n",
    "        plt.scatter(neuron_indices, total_results[layer].numpy())\n",
    "        plt.title(f'MLP Neuron Attribution Patch Values - Layer {layer}')\n",
    "        plt.xlabel('Neuron Index')\n",
    "        plt.ylabel('Estimated Logit Difference')\n",
    "        plt.grid()\n",
    "        plt.savefig(f'figs_addition/att_patching_neurons/layer{layer}_attribution_dist.png')\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "\n",
    "plot_mlp_attpatch(total_results)\n",
    "plot_neurons_attpatch(total_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating df with layer, neuron_idx, logit_difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neuron_df(total_results):\n",
    "    # Create lists to store data\n",
    "    layers = []\n",
    "    neuron_indices = []\n",
    "    logit_diffs = []\n",
    "    \n",
    "    # Extract data from total_results\n",
    "    for layer in range(total_results.shape[0]):\n",
    "        for neuron_idx in range(total_results[layer].shape[0]):\n",
    "            layers.append(layer)\n",
    "            neuron_indices.append(neuron_idx)\n",
    "            logit_diffs.append(float(total_results[layer][neuron_idx]))\n",
    "    \n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'layer': layers,\n",
    "        'neuron_idx': neuron_indices, \n",
    "        'logit_difference': logit_diffs\n",
    "    })\n",
    "    df.to_csv('data_addition/neuron_att_patching.csv', index=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_sorted_neuron_df():\n",
    "    df = pd.read_csv('data_addition/neuron_att_patching.csv')\n",
    "    df = df.sort_values('logit_difference', ascending=False)\n",
    "    return df\n",
    "\n",
    "def plot_neuron_impact_acrosslayers():\n",
    "    df = pd.read_csv('data_addition/neuron_att_patching.csv')\n",
    "    df = df.sort_values('logit_difference', ascending=False)\n",
    "    \n",
    "    # Calculate percentile ranks\n",
    "    total_neurons = len(df)\n",
    "    percentiles = [(i+1)/total_neurons * 100 for i in range(total_neurons)]\n",
    "    \n",
    "    plt.figure(figsize=(6,4))\n",
    "    scatter = plt.scatter(percentiles,\n",
    "                         df['logit_difference'], \n",
    "                         c=df['layer'],\n",
    "                         cmap='viridis',\n",
    "                         alpha=0.5)\n",
    "    plt.xscale('log')\n",
    "    plt.colorbar(scatter, label='Layer')\n",
    "    plt.title('Neuron Impact on Logit Difference Across Layers')\n",
    "    plt.xlabel('Percentile (Top %)')\n",
    "    plt.ylabel('Logit Difference')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.savefig('figs_addition/neuron_impact_acrosslayers.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "#create_neuron_df(total_results)\n",
    "#plot_neuron_impact_acrosslayers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting neurons back into model to see if we recover performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 13/13 [00:01<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of mean MLP activations: torch.Size([28, 16384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3917763/209883952.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load('data_addition/mean_mlp_activations.pt')\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def calc_mlp_meanablation(batch_size = 8, num_to_use = 100):\n",
    "    df = get_gen_math()\n",
    "    df = df.sample(n=num_to_use, random_state=42)\n",
    "    tokens = torch.stack([torch.tensor(x) for x in df['q_tok'].values])\n",
    "    mlps_total = []\n",
    "    for i in tqdm(range(0, len(tokens), batch_size)):\n",
    "        batch_tokens = tokens[i:i+batch_size].to('cuda')\n",
    "        mlps = []\n",
    "        with model.trace() as tracer:\n",
    "            with tracer.invoke(batch_tokens) as invoker_clean:\n",
    "                for layer in range(NLAYERS):\n",
    "                    mlp = model.transformer.h[layer].mlp.fc_out.input.save()\n",
    "                    mlps.append(mlp)\n",
    "        mlps_total.append(mlps)\n",
    "    mean_mlp_activations = torch.stack([\n",
    "        torch.mean(torch.cat([batch[layer][:,-1,:].cpu() for batch in mlps_total]), dim=0)\n",
    "        for layer in range(NLAYERS)\n",
    "    ])\n",
    "\n",
    "    print(f\"Shape of mean MLP activations: {mean_mlp_activations.shape}\")\n",
    "    # Save tensor to file\n",
    "    torch.save(mean_mlp_activations, 'data_addition/mean_mlp_activations.pt')\n",
    "    del mlps, mlps_total\n",
    "    #return mlps_total\n",
    "def get_mlp_meanablation():\n",
    "    return torch.load('data_addition/mean_mlp_activations.pt')\n",
    "\n",
    "calc_mlp_meanablation()\n",
    "mlps_total = get_mlp_meanablation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3917763/209883952.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load('data_addition/mean_mlp_activations.pt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5400)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()  \n",
    "def get_topk_neurons(k):\n",
    "    df = get_sorted_neuron_df()\n",
    "    top_k = df.head(k)\n",
    "    # Initialize list of lists for each layer\n",
    "    layer_neurons = [[] for _ in range(NLAYERS)]  # 28 layers based on context\n",
    "    # Group neurons by layer\n",
    "    for _, row in top_k.iterrows():\n",
    "        layer = int(row['layer'])\n",
    "        neuron = int(row['neuron_idx'])\n",
    "        layer_neurons[layer].append(neuron)  \n",
    "    return layer_neurons\n",
    "    \n",
    "def topk_neuron_ablate(k = 1, batch_size=8, num_to_use=100, verbose = False):\n",
    "    # Randomly sample num_to_use rows from df\n",
    "    df = get_correct_df()\n",
    "    df = df.sample(n=num_to_use, random_state=42)\n",
    "    neurons_layers = get_topk_neurons(k)\n",
    "\n",
    "    tokens = torch.stack([torch.tensor(x) for x in df['q_tok'].values])\n",
    "    answer_tokens = torch.stack([torch.tensor(x) for x in df['answer_tok'].values])[:,0]\n",
    "    \n",
    "    mlps_ablated_all = get_mlp_meanablation()\n",
    "    \n",
    "    all_correct = []\n",
    "    all_logit_diffs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(tokens), batch_size):\n",
    "            \n",
    "            batch_tokens = tokens[i:i+batch_size].to(device)\n",
    "            batch_answers = answer_tokens[i:i+batch_size]\n",
    "            mlps_ablated = mlps_ablated_all.unsqueeze(1).expand(-1, batch_tokens.shape[0], -1)\n",
    "            mlp_outs = []\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(batch_tokens) as invoker_clean:\n",
    "                    for layer in range(NLAYERS):\n",
    "                        mlp_out = model.transformer.h[layer].mlp.fc_out.input.save()\n",
    "                        mlp_outs.append(mlp_out)\n",
    "                og_logits = model.lm_head.output.save()\n",
    "            mlps = torch.stack([mlp_out[:,-1] for mlp_out in mlp_outs])\n",
    "            # Create tensor with same shape as mlps\n",
    "            insert = torch.zeros_like(mlps)\n",
    "            # Fill with ablated values initially\n",
    "            insert.copy_(mlps_ablated)\n",
    "            # For each layer, copy over the specified neuron values from mlps\n",
    "            for layer_idx, neuron_indices in enumerate(neurons_layers):\n",
    "                if neuron_indices:  # Only process if there are neurons for this layer\n",
    "                    insert[layer_idx, :, neuron_indices] = mlps[layer_idx, :, neuron_indices]\n",
    "            with model.trace() as tracer:\n",
    "                with tracer.invoke(batch_tokens) as invoker_clean:\n",
    "                    for layer in range(NLAYERS):\n",
    "                        model.transformer.h[layer].mlp.fc_out.input[:,-1] = insert[layer]\n",
    "                patched_logits = model.lm_head.output.save()\n",
    "            \n",
    "            patched_logits = patched_logits[:,-1].cpu()\n",
    "            og_logits = og_logits[:,-1].cpu()\n",
    "            model_answers = patched_logits.argmax(dim=-1)\n",
    "            correct = (model_answers == batch_answers).float()\n",
    "            logit_diff = og_logits[torch.arange(len(batch_answers)), batch_answers] - patched_logits[torch.arange(len(batch_answers)), batch_answers]\n",
    "            incorrect_indices = model_answers != batch_answers\n",
    "            if incorrect_indices.any() and verbose:\n",
    "                print('Incorrect predictions:')\n",
    "                print('Model answers:', model.tokenizer.batch_decode(model_answers[incorrect_indices]))\n",
    "                print('Actual answers:', model.tokenizer.batch_decode(batch_answers[incorrect_indices]))\n",
    "            all_correct.append(correct)\n",
    "            all_logit_diffs.append(logit_diff.float())\n",
    "            # Clean up variables\n",
    "            del mlps_ablated, batch_tokens, batch_answers, og_logits, patched_logits, model_answers, correct\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        \n",
    "    results = {'correct': torch.cat(all_correct), 'log_diff': torch.cat(all_logit_diffs)}\n",
    "    # Clean up remaining variables\n",
    "    del tokens, answer_tokens, all_correct, all_logit_diffs, neurons_layers, df\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "    return results\n",
    "topk_neuron_ablate(k=1000, num_to_use = 100)['correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 325x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 325x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>frac_neurons</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>logit_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7.367656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7.235125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7.120438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6.823406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.002</td>\n",
       "      <td>6.380844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.003</td>\n",
       "      <td>5.717250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.005</td>\n",
       "      <td>4.979187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>128</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.027</td>\n",
       "      <td>3.993750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.135</td>\n",
       "      <td>3.057625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>512</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.326</td>\n",
       "      <td>2.111500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.581</td>\n",
       "      <td>1.174375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2048</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.231125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4096</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.814</td>\n",
       "      <td>-0.771563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8192</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.882</td>\n",
       "      <td>-1.822125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16384</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.917</td>\n",
       "      <td>-2.882688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32768</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.937</td>\n",
       "      <td>-3.860437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>65536</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.946</td>\n",
       "      <td>-4.535875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>131072</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.946</td>\n",
       "      <td>-5.083437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>458752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         k  frac_neurons  accuracy  logit_diff\n",
       "0        1      0.000002     0.001    7.367656\n",
       "1        2      0.000004     0.001    7.235125\n",
       "2        4      0.000009     0.001    7.120438\n",
       "3        8      0.000017     0.001    6.823406\n",
       "4       16      0.000035     0.002    6.380844\n",
       "5       32      0.000070     0.003    5.717250\n",
       "6       64      0.000140     0.005    4.979187\n",
       "7      128      0.000279     0.027    3.993750\n",
       "8      256      0.000558     0.135    3.057625\n",
       "9      512      0.001116     0.326    2.111500\n",
       "10    1024      0.002232     0.581    1.174375\n",
       "11    2048      0.004464     0.718    0.231125\n",
       "12    4096      0.008929     0.814   -0.771563\n",
       "13    8192      0.017857     0.882   -1.822125\n",
       "14   16384      0.035714     0.917   -2.882688\n",
       "15   32768      0.071429     0.937   -3.860437\n",
       "16   65536      0.142857     0.946   -4.535875\n",
       "17  131072      0.285714     0.946   -5.083437\n",
       "18  458752      1.000000     0.996    0.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy_neurons_used(run = True):\n",
    "    maxk = len(get_sorted_neuron_df())\n",
    "    if run:\n",
    "        results = []\n",
    "        ks = [2**i for i in range(int(np.log2(maxk)))]\n",
    "        ks.append(maxk)\n",
    "        for k in tqdm(ks):\n",
    "            res = topk_neuron_ablate(k=k, num_to_use=1000)\n",
    "            results.append({\n",
    "                'k': k,\n",
    "                'frac_neurons': k/maxk,\n",
    "                'accuracy': res['correct'].mean().item(),\n",
    "                'logit_diff': res['log_diff'].mean().item()\n",
    "            })\n",
    "        df = pd.DataFrame(results)\n",
    "        df.to_csv('data_addition/neurons_vs_metrics.csv', index=False)\n",
    "    df = pd.read_csv('data_addition/neurons_vs_metrics.csv')\n",
    "    \n",
    "    for metric in ['accuracy', 'logit_diff']:\n",
    "        plt.figure(figsize=(3.25,2))\n",
    "        plt.semilogx(df['frac_neurons'], df[metric], 'o-', markersize=4)\n",
    "        plt.xlabel('Fraction of Neurons')\n",
    "        plt.ylabel(metric.title())\n",
    "        plt.title(f'Model Performance vs Fraction of Neurons Used\\n(Metric: {metric.replace(\"_\", \" \").title()})')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'figs_addition/neurons_vs_{metric}.png', bbox_inches = 'tight', dpi = 300)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    return df\n",
    "    #topk_neuron_ablate(k=1000, num_to_use = 100)['correct'].mean()\n",
    "accuracy_neurons_used(run = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
